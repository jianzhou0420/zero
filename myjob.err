/home/a1946536/.conda/envs/zero/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------

Missing logger folder: /hpcfs/users/a1946536/zero/2_Train/2025_02_22__15-05_expBaseV5_test
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

  | Name  | Type               | Params
---------------------------------------------
0 | model | SimplePolicyPTV3CA | 68.3 M
---------------------------------------------
68.3 M    Trainable params
0         Non-trainable params
68.3 M    Total params
273.342   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/home/a1946536/.conda/envs/zero/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:104: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.
/home/a1946536/.conda/envs/zero/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:104: Total length of `CombinedLoader` across ranks is zero. Please make sure this was your intention.
`Trainer.fit` stopped: No training batches.
