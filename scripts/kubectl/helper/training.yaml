apiVersion: batch/v1
kind: Job
metadata:
  name: exp # Your training job name
spec:
  backoffLimit: 0   # add this line so --> If your pod failed, the training job will stop.
  template:
    spec:
      restartPolicy: Never
      imagePullSecrets:
        - name: gitlab-docker-secret
      volumes:
        - name: shared-memory # This is to resolve the dataloader OOM issue.
          emptyDir:
            medium: Memory
        - name: dataset-volume
          persistentVolumeClaim:
            claimName: rlbench-pvc      # <------- your PVC name    kubectl get pvc

      containers:
        - name: zero-container # It is recommended to name your container according to the project
          image: docker.aiml.team/jian.zhou/test:latest # You can reuse this image for different projects if their python dependencies are the same.
          imagePullPolicy: Always
          stdin: true
          tty: true
          command: ["/bin/bash", "-c"]
          args: 
              - |
                cd /data/zero
                git pull
                pip install -e .
                python -c "import torch; print(torch.cuda.is_available());print(torch.__version__);print(torch.version.cuda)"
                nvidia-smi
                python  -m zero.expBaseV5.trainer_expbase \
                        --exp-config /data/zero/zero/expBaseV5/config/expBase_Lotus.yaml \
                        name expBaseV5_test \
                        dataset augment\
                        num_gpus 4 \
                        epoches 1500 \
                        batch_size 1 \
                        TRAIN_DATASET.num_points 100000 \
                        TRAIN_DATASET.pos_bins 75 \
                        TRAIN_DATASET.pos_bin_size 0.001\
                        MODEL.action_config.pos_bins 75\
                        MODEL.action_config.pos_bin_size 0.001 \
                       


          resources:
            limits:
              nvidia.com/gpu: 4           # <------- If you don't need any of GPUs, Please comment-out this line.
              cpu: 16
              memory: 128Gi
            requests:
              nvidia.com/gpu: 4           # <------- If you don't need any of GPUs, Please comment-out this line.
              cpu: 16
              memory: 64Gi

          volumeMounts:
            - name: dataset-volume
              mountPath: /data
            - name: shared-memory
              mountPath: /dev/shm
          env:
            - name: GITLAB_TOKEN
              valueFrom:
                secretKeyRef:
                    name: gitlab-token  # kubectl get secrets
                    key:  access-token